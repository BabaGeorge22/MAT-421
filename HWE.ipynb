{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMob/MallXjmnMWXw8VCZvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BabaGeorge22/MAT-421/blob/main/HWE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module E Homework: 3.2-3.3 - George Tome"
      ],
      "metadata": {
        "id": "Ns5t50IHXVlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 3.2 - Continuity and Differentiation**"
      ],
      "metadata": {
        "id": "QzRq7U-6X92C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuity: A function has no sudden jumps. Small changes in x lead to small changes in f(x).\n",
        "\n",
        "Derivative: Measures how f(x) changes with respect to x. For multiple variables, it talks about partial derivatives.\n",
        "\n",
        "Chain Rule: Composing two differentiable functions allows one to find the derivative of the composition by multiplying their respective derivatives."
      ],
      "metadata": {
        "id": "0kYB5IIvYGL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy\n",
        "\n",
        "# Differentiation\n",
        "x = sympy.Symbol('x', real=True)\n",
        "f = x**3 - 3*x + 5  # Some single-variable function\n",
        "\n",
        "fprime = sympy.diff(f, x)  # derivative of f w.r.t x\n",
        "print(\"f(x) =\", f)\n",
        "print(\"f'(x) =\", fprime)\n",
        "\n",
        "# Derivative at x=2\n",
        "val = fprime.subs(x, 2)\n",
        "print(\"Derivative at x=2:\", val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEmsoaTKYuhy",
        "outputId": "f890739f-8287-429a-e1f1-1c1ac9052d1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f(x) = x**3 - 3*x + 5\n",
            "f'(x) = 3*x**2 - 3\n",
            "Derivative at x=2: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use sympy.diff to find the derivative of a simple polynomial.\n",
        "\n",
        "Evaluate it at a specific point."
      ],
      "metadata": {
        "id": "yuEorCeeY-aU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Taylor's Theorem**"
      ],
      "metadata": {
        "id": "np8Zo74rZGkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taylor expansion approximates a function near a point by a polynomial.\n",
        "\n",
        "In multiple variables, expand around a point, keeping terms linear for approximation.\n",
        "\n",
        "Higher order expansions give more accurate approximations, but also more computation."
      ],
      "metadata": {
        "id": "9FiNugAKZNhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy\n",
        "\n",
        "x = sympy.Symbol('x', real=True)\n",
        "f = sympy.exp(x)  # e^x\n",
        "x0 = 0            # Maclaurin series\n",
        "\n",
        "# Get the first few terms of the Taylor series\n",
        "taylor_expansion = f.series(x, x0, 4)  # up to x^3\n",
        "print(\"e^x approximated near 0:\", taylor_expansion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXC_ALkwZXuc",
        "outputId": "a8c0e976-1832-4a81-92fd-b545ee5e0e24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e^x approximated near 0: 1 + x + x**2/2 + x**3/6 + O(x**4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f.series(x, 0, 4) gives a polynomial expansion of e^x.\n",
        "\n",
        "This approximates e^x near x=0."
      ],
      "metadata": {
        "id": "K8Kws_vyZnMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FUPUx3ShaE7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 3.3 - Optimization with Gradient Descent**"
      ],
      "metadata": {
        "id": "gTNyx4VpZ9MA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unconstrained Optimization: We want to find an x that minimizes f(x) without additional constraints.\n",
        "\n",
        "Gradient Descent: Iterative process where we update x in the opposite direction of âˆ‡f(x).\n",
        "\n",
        "Step Size: Controls how big a step we take each iteration. If it's too large, we might diverge, too small, we converge slowly."
      ],
      "metadata": {
        "id": "LsYtHLX-aGQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def f(x):\n",
        "    # 1D function: f(x) = (x-3)^2\n",
        "    return (x - 3)**2\n",
        "\n",
        "def grad_f(x):\n",
        "    # Derivative of f(x) = 2(x-3)\n",
        "    return 2*(x - 3)\n",
        "\n",
        "# Gradient Descent\n",
        "x_current = 10.0   # initial guess\n",
        "lr = 0.1           # learning rate\n",
        "for i in range(20):\n",
        "    x_current = x_current - lr * grad_f(x_current)\n",
        "\n",
        "print(\"Approximate minimizer:\", x_current)\n",
        "print(\"f(x) at that point:\", f(x_current))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RQ6IMIUakxk",
        "outputId": "079ae898-4209-4ae9-823a-47ad7a93d599"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate minimizer: 3.0807045053224793\n",
            "f(x) at that point: 0.00651321717934609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a simple function f(x).\n",
        "\n",
        "Its gradient is grad_f(x).\n",
        "\n",
        "Each iteration, move x in the negative gradient direction."
      ],
      "metadata": {
        "id": "7iiCeIchauIY"
      }
    }
  ]
}